{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4636b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import sys , os\n",
    "sys.path.append(\"..\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9659a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "당신은 부동산 대행사 업체에서 입지 분석 전문가로 일하고 있는 사람입니다.\n",
    "상사의 명령을 반드시 수행합니다.\n",
    "\"\"\"\n",
    "\n",
    "question = \"\"\"\n",
    "오늘 날씨는 2025년 10월 24일 입니다.\n",
    "경기도 분당구 정자동 쪽에 사업을 시작하고 싶습니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76702a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"error\":{\"message\":\"Invalid model 'llama-3.1-sonar-small-128k-online'. Permitted models can be found in the documentation at https://docs.perplexity.ai/getting-started/models.\",\"type\":\"invalid_model\",\"code\":400}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def call_llm(question:str):\n",
    "    PERPLEXXITY_KEY = os.getenv(\"PERPLEXXITY_KEY\")\n",
    "    url = \"https://api.perplexity.ai/chat/completions\"\n",
    "    payload = {\n",
    "        \"model\": \"llama-3.1-sonar-small-128k-online\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\":question\n",
    "            }\n",
    "        ],\n",
    "        \"temperature\": 0,\n",
    "        \"return_citations\": False\n",
    "    }\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"content-type\": \"application/json\",\n",
    "        \"authorization\": f\"Bearer {PERPLEXXITY_KEY}\"\n",
    "    }\n",
    "    response = requests.post(url, json=payload, headers=headers)    \n",
    "    return response\n",
    "\n",
    "\n",
    "print(call_llm(question).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2ea089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StructuredTool(name='web_search_exa', description='Search the web using Exa AI - performs real-time web searches and can scrape content from specific URLs. Supports configurable result counts and returns the content from the most relevant websites.', args_schema={'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'Search query'}, 'numResults': {'type': 'number', 'description': 'Number of search results to return (default: 5)'}}, 'required': ['query'], 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x12d52cd60>), StructuredTool(name='get_code_context_exa', description=\"Search and get relevant context for any programming task. Exa-code has the highest quality and freshest context for libraries, SDKs, and APIs. Use this tool for ANY question or task for related to programming. RULE: when the user's query contains exa-code or anything related to code, you MUST use this tool.\", args_schema={'type': 'object', 'properties': {'query': {'type': 'string', 'description': \"Search query to find relevant context for APIs, Libraries, and SDKs. For example, 'React useState hook examples', 'Python pandas dataframe filtering', 'Express.js middleware', 'Next js partial prerendering configuration'\"}, 'tokensNum': {'anyOf': [{'type': 'string', 'const': 'dynamic'}, {'type': 'number', 'minimum': 1000, 'maximum': 50000}], 'default': 'dynamic', 'description': \"Token allocation strategy: 'dynamic' (default, token-efficient, returns the 100-1000+ most useful tokens), 1000-50000 tokens (returns a specific number of tokens). Use 'dynamic' for optimal token efficiency - only specify a concrete number of tokens if 'dynamic' mode doesn't return the right information.\"}}, 'required': ['query'], 'additionalProperties': False, '$schema': 'http://json-schema.org/draft-07/schema#'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x1464daca0>)]\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from labbing_test.mcp_client import get_tools\n",
    "tools = await get_tools()\n",
    "print(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484984cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-commander",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
