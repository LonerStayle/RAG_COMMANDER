{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3e470f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\PythonProject\\RAG_COMMANDER\\src\n",
      "c:\\PythonProject\\RAG_COMMANDER\\src\\agents\\main\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "\n",
    "src_path = Path(os.getcwd()).resolve().parents[1]  \n",
    "sys.path.append(str(src_path))\n",
    "\n",
    "print(sys.path[-1])  \n",
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efa8f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting main_agent.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile main_agent.py\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph.state import Command, Literal\n",
    "from agents.state.start_state import StartConfirmation, StartInput\n",
    "from agents.state.main_state import MainState\n",
    "from utils.llm import LLMProfile\n",
    "from utils.util import get_today_str\n",
    "from langchain_core.messages import HumanMessage, get_buffer_string, AIMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from prompts import PromptManager, PromptType\n",
    "from agents.analysis.analysis_graph import analysis_graph\n",
    "from agents.jung_min_jae.jung_min_jae_agent import report_graph\n",
    "from copy import deepcopy\n",
    "\n",
    "start_llm = LLMProfile.chat_bot_llm()\n",
    "messages_key = MainState.KEY.messages\n",
    "start_input_key = MainState.KEY.start_input\n",
    "analysis_outputs_key = MainState.KEY.analysis_outputs\n",
    "status_key = MainState.KEY.status\n",
    "\n",
    "\n",
    "def start_confirmation(\n",
    "    state: MainState,\n",
    ") -> Command[Literal[\"start\", \"__end__\"]]:\n",
    "\n",
    "    parser_llm = start_llm.with_structured_output(StartConfirmation)\n",
    "    messages_str = get_buffer_string(messages=state[messages_key])\n",
    "\n",
    "    prompt = PromptManager(PromptType.MAIN_START_CONFIRMATION).get_prompt(\n",
    "        messages=messages_str\n",
    "    )\n",
    "    response: StartConfirmation = parser_llm.invoke([HumanMessage(content=prompt)])\n",
    "\n",
    "    if response.confirm == False:\n",
    "        return Command(\n",
    "            goto=END, update={messages_key: [AIMessage(content=response.question)]}\n",
    "        )\n",
    "    else:\n",
    "        return Command(\n",
    "            goto=\"start\",\n",
    "            update={messages_key: [AIMessage(content=response.verification)]},\n",
    "        )\n",
    "\n",
    "\n",
    "def start(state: MainState) -> MainState:\n",
    "    parser_model = start_llm.with_structured_output(StartInput)\n",
    "    prompt = PromptManager(PromptType.MAIN_START).get_prompt(\n",
    "        messages=get_buffer_string(state[messages_key]), date=get_today_str()\n",
    "    )\n",
    "    response: StartInput = parser_model.invoke([HumanMessage(content=prompt)])\n",
    "    return {start_input_key: response.model_dump(), status_key: \"ANALYSIS\"}\n",
    "\n",
    "\n",
    "def analysis_graph_node(state: MainState) -> MainState:\n",
    "    result = analysis_graph.invoke({\"start_input\": deepcopy(state[start_input_key])})\n",
    "    return {\n",
    "        \"analysis_outputs\": result.get(\"analysis_outputs\", {}),\n",
    "        status_key: \"JUNG_MIN_JAE\"\n",
    "    }\n",
    "\n",
    "\n",
    "def jung_min_jae_graph(state: MainState) -> MainState:\n",
    "    result = report_graph.invoke({\"start_input\": deepcopy(state[start_input_key]),\n",
    "                                  \"analysis_outputs\": deepcopy(state[analysis_outputs_key]),\n",
    "                                  \"segment\":1\n",
    "                                  })\n",
    "    return {\n",
    "        \"final_report\": result[\"final_report\"],\n",
    "        status_key:\"RENDERING\"\n",
    "    }\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(MainState)\n",
    "\n",
    "start_confirmation_key = \"start_confirmation\"\n",
    "start_key = \"start\"\n",
    "analysis_graph_key = \"analysis_graph\"\n",
    "jung_min_jae_key = \"jung_min_jae_graph\"\n",
    "\n",
    "graph_builder.add_node(start_confirmation_key, start_confirmation)\n",
    "graph_builder.add_node(start_key, start)\n",
    "graph_builder.add_node(analysis_graph_key, analysis_graph_node)\n",
    "graph_builder.add_node(jung_min_jae_key, jung_min_jae_graph)\n",
    "\n",
    "graph_builder.add_edge(START, start_confirmation_key)\n",
    "graph_builder.add_edge(start_key, analysis_graph_key)\n",
    "graph_builder.add_edge(analysis_graph_key, jung_min_jae_key)\n",
    "graph_builder.add_edge(analysis_graph_key, END)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0533bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\PythonProject\\RAG_COMMANDER\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'content' from 'langchain_core.messages' (c:\\PythonProject\\RAG_COMMANDER\\.venv\\Lib\\site-packages\\langchain_core\\messages\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmain_agent\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m graph_builder\n\u001b[32m      2\u001b[39m graph = graph_builder.compile()\n\u001b[32m      3\u001b[39m graph\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\PythonProject\\RAG_COMMANDER\\src\\agents\\main\\main_agent.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlanggraph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstate\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Command, Literal\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magents\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstate\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstart_state\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StartConfirmation, StartInput\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\PythonProject\\RAG_COMMANDER\\.venv\\Lib\\site-packages\\langchain_openai\\__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"Module for OpenAI integrations.\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AzureChatOpenAI, ChatOpenAI\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01membeddings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AzureOpenAIEmbeddings, OpenAIEmbeddings\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AzureOpenAI, OpenAI\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\PythonProject\\RAG_COMMANDER\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"Module for OpenAI chat models.\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat_models\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mazure\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AzureChatOpenAI\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat_models\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[32m      6\u001b[39m __all__ = [\u001b[33m\"\u001b[39m\u001b[33mAzureChatOpenAI\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mChatOpenAI\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\PythonProject\\RAG_COMMANDER\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\azure.py:20\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseModel, Field, SecretStr, model_validator\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping_extensions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Self\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat_models\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseChatOpenAI\n\u001b[32m     22\u001b[39m logger = logging.getLogger(\u001b[34m__name__\u001b[39m)\n\u001b[32m     25\u001b[39m _BM = TypeVar(\u001b[33m\"\u001b[39m\u001b[33m_BM\u001b[39m\u001b[33m\"\u001b[39m, bound=BaseModel)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\PythonProject\\RAG_COMMANDER\\.venv\\Lib\\site-packages\\langchain_openai\\chat_models\\base.py:60\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlanguage_models\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     38\u001b[39m     BaseChatModel,\n\u001b[32m     39\u001b[39m     LangSmithParams,\n\u001b[32m     40\u001b[39m )\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmessages\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     42\u001b[39m     AIMessage,\n\u001b[32m     43\u001b[39m     AIMessageChunk,\n\u001b[32m   (...)\u001b[39m\u001b[32m     58\u001b[39m     is_data_content_block,\n\u001b[32m     59\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmessages\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m content \u001b[38;5;28;01mas\u001b[39;00m types\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmessages\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     62\u001b[39m     InputTokenDetails,\n\u001b[32m     63\u001b[39m     OutputTokenDetails,\n\u001b[32m     64\u001b[39m     UsageMetadata,\n\u001b[32m     65\u001b[39m )\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmessages\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mblock_translators\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     67\u001b[39m     _convert_from_v03_ai_message,\n\u001b[32m     68\u001b[39m     convert_to_openai_data_block,\n\u001b[32m     69\u001b[39m )\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'content' from 'langchain_core.messages' (c:\\PythonProject\\RAG_COMMANDER\\.venv\\Lib\\site-packages\\langchain_core\\messages\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from main_agent import graph_builder\n",
    "graph = graph_builder.compile()\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfd5a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.format_message import format_message\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from agents.state.main_state import MainState\n",
    "messages_key = MainState.KEY.messages\n",
    "checkpointer = InMemorySaver()\n",
    "graph = graph_builder.compile(checkpointer = checkpointer)\n",
    "\n",
    "thread = {\"configurable\": {\"thread_id\":\"1\"}}\n",
    "result = graph.invoke(\n",
    "    {\n",
    "        messages_key : [HumanMessage(content = \"경기도 분당구 정자동 백현로 206 근처를 분석하고 싶고 규모는 대단지, 세대수는 1000세대 정도 생각합니다. \")]\n",
    "    },\n",
    "    config = thread\n",
    ")\n",
    "\n",
    "format_message(result[messages_key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bf2917",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971d5bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1670b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result['final_report'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d5f644",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG_COMMANDER",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
