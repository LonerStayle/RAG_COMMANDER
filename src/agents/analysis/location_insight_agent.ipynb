{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc0c7941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "allforone\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_teddynote import logging\n",
    "logging.langsmith(\"allforone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f1b565",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from agents.state.analysis_state import LocationInsightState\n",
    "from agents.state.start_state import StartInput\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, ToolMessage\n",
    "from utils.util import get_today_str\n",
    "from utils.llm import LLMProfile\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from prompts import PromptManager, PromptType\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from tools.kostat_api import get_move_population, system_prompt\n",
    "import json\n",
    "import asyncio\n",
    "\n",
    "@tool(parse_docstring=True)\n",
    "def think_tool(reflection: str) -> str:\n",
    "    \"\"\"\n",
    "    [역할]\n",
    "    당신은 입지/호재 정리 전문가의 내부 반성·점검(Reflection) 담당자입니다.\n",
    "    최종 보고서에 들어갈 본문(Markdown)을 쓰기 직전에, 데이터 품질·핵심 수치·리스크·보고서용 한 줄 메시지를 짧고 구조적으로 요약해 think_tool에 기록합니다. 이 반성문은 내부용이며, 최종 보고서에 직접 노출되지 않습니다.\n",
    "\n",
    "    [언제 호출할 것인지]\n",
    "    - 데이터 수집/정제 → 핵심 수치 산출 → 시계열 해석을 마친 직후 1회 호출(필수)\n",
    "    - 추가 데이터로 최신 데이터로 바뀌면 갱신 시마다 1회 재호출(선택)\n",
    "\n",
    "    [강력 지시]\n",
    "    - 해당 지역에 관련된 내용만 기록\n",
    "    - 허상 가정,출처 수치 금지\n",
    "    - 다음 단계(보고서 에이전트)가 바로 쓸 수 있는 한 줄 핵심 메시지 포함\n",
    "\n",
    "    [나쁜 예]\n",
    "    - “경제가 좋아진듯함. 분위기 좋음.”(수치·기간·단위·근거 없음)\n",
    "    - “인근 해운대의 입지지는 이렇다~”(대상 지역 외 서술)\n",
    "    - “향후 집값 상승 확실.”(근거 없는 단정)\n",
    "\n",
    "    [검증 체크리스트]\n",
    "    - 정량 수치가 어긋난 것 이 있는가?\n",
    "    - GPT가 시계열 판단하기에 좋은 형식으로 되어있는가?\n",
    "    - 잘못된 내용은 없는가?\n",
    "    \"\"\"\n",
    "    return f\"Reflection recorded: {reflection}\"\n",
    "\n",
    "output_key = LocationInsightState.KEY.location_insight_output\n",
    "start_input_key = LocationInsightState.KEY.start_input\n",
    "rag_context_key = LocationInsightState.KEY.rag_context\n",
    "messages_key = LocationInsightState.KEY.messages\n",
    "target_area_key = StartInput.KEY.target_area\n",
    "main_type_key = StartInput.KEY.main_type\n",
    "total_units_key = StartInput.KEY.total_units\n",
    "web_context_key = LocationInsightState.KEY.web_context\n",
    "kakao_api_distance_context_key = LocationInsightState.KEY.kakao_api_distance_context\n",
    "\n",
    "\n",
    "llm = LLMProfile.analysis_llm()\n",
    "tool_list = [think_tool]\n",
    "llm_with_tools = llm.bind_tools(tool_list)\n",
    "tool_node = ToolNode(tool_list)\n",
    "\n",
    "from tools.gemini_search_tool import gemini_search\n",
    "\n",
    "\n",
    "def gemini_search_tool(state: LocationInsightState) -> LocationInsightState:\n",
    "    start_input = state[start_input_key]\n",
    "    target_area = start_input[target_area_key]\n",
    "    target_main_type = start_input[main_type_key]\n",
    "    total_units = start_input[total_units_key]\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    <CONTEXT>\n",
    "    주소: {target_area}\n",
    "    규모: {total_units}세대\n",
    "    타입: {target_main_type}\n",
    "    </CONTEXT>\n",
    "    <GOAL>\n",
    "    <CONTEXT> 주변 분양호재를 <OUTPUT>을 참조해서 json 형식으로 출력해주세요\n",
    "    </GOAL>\n",
    "    <OUTPUT>\n",
    "    {{\n",
    "      \"분양호재\": [\n",
    "        {{\n",
    "          \"name\": \"\",\n",
    "          \"location\": \"\",\n",
    "          \"description\": \"\",\n",
    "          \"status\": \"\"\n",
    "        }}\n",
    "      ]\n",
    "    }}\n",
    "    </OUTPUT>\n",
    "    \"\"\"\n",
    "    result = gemini_search(prompt)\n",
    "\n",
    "    return {**state, web_context_key: result}\n",
    "\n",
    "from tools.kakao_api_distance_tool import get_location_profile\n",
    "def kakao_api_distance_tool(stat: LocationInsightState) -> LocationInsightState:\n",
    "    start_input = stat[start_input_key]\n",
    "    target_area = start_input[target_area_key]\n",
    "    result = get_location_profile(target_area)\n",
    "    return {**state, kakao_api_distance_context_key: result}\n",
    "\n",
    "def analysis_setting(state: LocationInsightState) -> LocationInsightState:\n",
    "    start_input = state[start_input_key]\n",
    "    target_area = start_input[target_area_key]\n",
    "    total_units = start_input[total_units_key]\n",
    "    main_type = start_input[main_type_key]\n",
    "    rag_context = state[rag_context_key]\n",
    "    web_context = state[web_context_key]\n",
    "    kakao_api_distance_context = state[kakao_api_distance_context_key]\n",
    "\n",
    "    system_prompt = PromptManager(PromptType.LOCATION_INSIGHT_SYSTEM).get_prompt()\n",
    "    human_prompt = PromptManager(PromptType.LOCATION_INSIGHT_HUMAN).get_prompt(\n",
    "        target_area=target_area,\n",
    "        total_units=total_units,\n",
    "        main_type=main_type,\n",
    "        date=get_today_str(),\n",
    "        web_context=web_context,\n",
    "        rag_context=rag_context,\n",
    "        kakao_api_distance_context=kakao_api_distance_context,\n",
    "    ) \n",
    "    messages = [\n",
    "        SystemMessage(content=system_prompt),\n",
    "        HumanMessage(content=human_prompt)\n",
    "    ]\n",
    "    return {**state, messages_key: messages}\n",
    "\n",
    "def agent(state: LocationInsightState) -> LocationInsightState:\n",
    "    me"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
